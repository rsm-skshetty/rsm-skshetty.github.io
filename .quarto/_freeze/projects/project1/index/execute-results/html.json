{
  "hash": "4bda64a5690142154679ffe5befc623f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A Replication of Karlan and List (2007)\"\nauthor: \"Samiksha\"\ndate: today\ncallout-appearance: minimal # this hides the blue \"i\" icon on .callout-notes\n---\n\n\n## Introduction\n\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\nIn the early 2000s, economists Dean Karlan and John List partnered with a politically oriented nonprofit organization to run a large-scale natural field experiment on charitable giving. The organization sent out over 50,000 fundraising letters to prior donors, randomly assigning each recipient to a different version of the letter.\n\nThe central research question was: Does offering a matching grant increase the likelihood and amount of charitable donations?\n\nTo answer this, recipients were randomly assigned to:\n- A control group that received a standard appeal,\n- A treatment group that was told a generous donor would match their gift at one of several ratios: 1:1, 2:1, or 3:1.\n\nOther variables were randomized as well:\n- The maximum amount of the matching grant (\\$25k, \\$50k, \\$100k, or unstated),\n- The suggested donation amount, based on their previous giving.\n\nThis rich experimental design allows for credible causal inference on how donors respond to match offers — both in whether they give at all (extensive margin) and how much they give (intensive margin). It’s one of the first large-scale field experiments to rigorously test “price” sensitivity in fundraising using real behavior and real money.\n\nThis project seeks to replicate their results.\n\n\n## Data\n\n### Description\n\n::: {#load-and-describe-data .cell .fig-cap-location-bottom execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n\n# Load the actual dataset you just uploaded\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Preview the first few rows\nprint(data.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n0          0        1  Control       0       0   Control       0       0   \n1          0        1  Control       0       0   Control       0       0   \n2          1        0        1       0       0  $100,000       0       0   \n3          1        0        1       0       0  Unstated       0       0   \n4          1        0        1       0       0   $50,000       0       1   \n\n   size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n\n   ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n0       2.10          28517.0  0.499807      0.324528            1.0  \n1        NaN              NaN       NaN           NaN            NaN  \n2       2.48          51175.0  0.721941      0.192668            1.0  \n3       2.65          79269.0  0.920431      0.412142            1.0  \n4       1.85          40908.0  0.416072      0.439965            1.0  \n\n[5 rows x 51 columns]\n```\n:::\n:::\n\n\n::: {#cb674e2f .cell execution_count=2}\n``` {.python .cell-code}\nprint(data.shape)\nprint(data.info())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(50083, 51)\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n```\n:::\n:::\n\n\n::: {#cell-data-summary .cell execution_count=3}\n``` {.python .cell-code}\n# Summary statistics for all variables\ndata.describe()\n```\n\n::: {#data-summary .cell-output .cell-output-display execution_count=3}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>treatment</th>\n      <th>control</th>\n      <th>ratio2</th>\n      <th>ratio3</th>\n      <th>size25</th>\n      <th>size50</th>\n      <th>size100</th>\n      <th>sizeno</th>\n      <th>askd1</th>\n      <th>askd2</th>\n      <th>...</th>\n      <th>redcty</th>\n      <th>bluecty</th>\n      <th>pwhite</th>\n      <th>pblack</th>\n      <th>page18_39</th>\n      <th>ave_hh_sz</th>\n      <th>median_hhincome</th>\n      <th>powner</th>\n      <th>psch_atlstba</th>\n      <th>pop_propurban</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>50083.000000</td>\n      <td>...</td>\n      <td>49978.000000</td>\n      <td>49978.000000</td>\n      <td>48217.000000</td>\n      <td>48047.000000</td>\n      <td>48217.000000</td>\n      <td>48221.000000</td>\n      <td>48209.000000</td>\n      <td>48214.000000</td>\n      <td>48215.000000</td>\n      <td>48217.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.666813</td>\n      <td>0.333187</td>\n      <td>0.222311</td>\n      <td>0.222211</td>\n      <td>0.166723</td>\n      <td>0.166623</td>\n      <td>0.166723</td>\n      <td>0.166743</td>\n      <td>0.222311</td>\n      <td>0.222291</td>\n      <td>...</td>\n      <td>0.510245</td>\n      <td>0.488715</td>\n      <td>0.819599</td>\n      <td>0.086710</td>\n      <td>0.321694</td>\n      <td>2.429012</td>\n      <td>54815.700533</td>\n      <td>0.669418</td>\n      <td>0.391661</td>\n      <td>0.871968</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.471357</td>\n      <td>0.471357</td>\n      <td>0.415803</td>\n      <td>0.415736</td>\n      <td>0.372732</td>\n      <td>0.372643</td>\n      <td>0.372732</td>\n      <td>0.372750</td>\n      <td>0.415803</td>\n      <td>0.415790</td>\n      <td>...</td>\n      <td>0.499900</td>\n      <td>0.499878</td>\n      <td>0.168560</td>\n      <td>0.135868</td>\n      <td>0.103039</td>\n      <td>0.378105</td>\n      <td>22027.316665</td>\n      <td>0.193405</td>\n      <td>0.186599</td>\n      <td>0.258633</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.009418</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5000.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.755845</td>\n      <td>0.014729</td>\n      <td>0.258311</td>\n      <td>2.210000</td>\n      <td>39181.000000</td>\n      <td>0.560222</td>\n      <td>0.235647</td>\n      <td>0.884929</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.872797</td>\n      <td>0.036554</td>\n      <td>0.305534</td>\n      <td>2.440000</td>\n      <td>50673.000000</td>\n      <td>0.712296</td>\n      <td>0.373744</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.938827</td>\n      <td>0.090882</td>\n      <td>0.369132</td>\n      <td>2.660000</td>\n      <td>66005.000000</td>\n      <td>0.816798</td>\n      <td>0.530036</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.989622</td>\n      <td>0.997544</td>\n      <td>5.270000</td>\n      <td>200001.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 48 columns</p>\n</div>\n```\n:::\n:::\n\n\n:::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|----------------------|---------------------------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n\n::::\n\n\n### Balance Test \n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n::: {#balance-ttests .cell execution_count=4}\n``` {.python .cell-code}\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.formula.api as smf\n\n# Balance test on observed covariates\nbalance_vars = ['ask1', 'years', 'female', 'median_hhincome','mrm2','couple']\n\nfor var in balance_vars:\n    treated = data.loc[data['treatment'] == 1, var].dropna()\n    control = data.loc[data['treatment'] == 0, var].dropna()\n\n    x1, x2 = treated.mean(), control.mean()\n    s1, s2 = treated.std(), control.std()\n    n1, n2 = len(treated), len(control)\n\n    # Manual t-statistic (pooled standard error)\n    se = np.sqrt((s1**2 / n1) + (s2**2 / n2))\n    t_stat = (x1 - x2) / se\n    df = min(n1, n2) - 1\n    p_val = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n\n    print(f\"\\nVariable: {var}\")\n    print(f\"Manual t-test: t = {t_stat:.4f}, p = {p_val:.4f}\")\n\n    # Linear regression\n    model = smf.ols(f\"{var} ~ treatment\", data=data).fit()\n    coef = model.params['treatment']\n    p = model.pvalues['treatment']\n    print(f\"Regression: Coef = {coef:.4f}, p = {p:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nVariable: ask1\nManual t-test: t = 0.9730, p = 0.3306\nRegression: Coef = 0.9154, p = 0.3425\n\nVariable: years\nManual t-test: t = -1.0909, p = 0.2753\nRegression: Coef = -0.0575, p = 0.2700\n\nVariable: female\nManual t-test: t = -1.7535, p = 0.0795\nRegression: Coef = -0.0075, p = 0.0787\n\nVariable: median_hhincome\nManual t-test: t = -0.7433, p = 0.4573\nRegression: Coef = -157.9255, p = 0.4583\n\nVariable: mrm2\nManual t-test: t = 0.1195, p = 0.9049\nRegression: Coef = 0.0137, p = 0.9049\n\nVariable: couple\nManual t-test: t = -0.5823, p = 0.5604\nRegression: Coef = -0.0016, p = 0.5594\n```\n:::\n:::\n\n\nThe balance tests above check whether the treatment and control groups differ before the intervention on observable characteristics.\nKey insights include:\n- All p-values are greater than 0.05, meaning no statistically significant differences between groups\n- T-test statistics and regression coefficients are numerically equivalent, confirming the equivalence of these two methods in this context\n\nThis result is consistent with the claim that random assignment was successful — any differences observed in donation behavior later on can be attributed to the treatment itself, not pre-existing group differences.\n\n\n## Experimental Results\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. \n\nTo evaluate the effect of matched donations on the likelihood of giving (i.e., the response rate), we first compare the proportion of people who donated in the treatment vs. control groups.\n\nBelow is a simple bar plot showing the share of donors in each group.\n\n::: {#cell-barplot-response-rate .cell execution_count=5}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\n# Calculate donation rates\ndonation_rates = data.groupby(\"treatment\")[\"gave\"].mean()\nlabels = [\"Control\", \"Treatment\"]\n\n# Create bar plot\nplt.figure(figsize=(6, 4))\nbars = plt.bar(labels, donation_rates, color=[\"skyblue\", \"lightgreen\"])\nplt.title(\"Proportion of Donors by Treatment Status\")\nplt.ylabel(\"Proportion Who Donated\")\nplt.ylim(0, max(donation_rates)*1.2)\n\n# Annotate bar heights\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.0005, f\"{yval:.3f}\", ha=\"center\", va=\"bottom\")\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Proportion of Donors by Treatment Status](index_files/figure-html/barplot-response-rate-output-1.png){#barplot-response-rate width=565 height=373 fig-align='center'}\n:::\n:::\n\n\nThe bar plot shows that the treatment group — those who received a matching donation offer — had a higher donation rate than the control group.\n\nThis suggests that matched donations may be effective at increasing the likelihood of contributing. We'll test the statistical significance of this next using t-tests and regression.\n\n\nWe now formally test whether the treatment group was significantly more likely to donate than the control group. \nWe use two methods:\n1. A manual t-test, comparing donation rates across groups  \n2. A linear regression of gave on treatment\n\nThese approaches should return numerically identical p-values and treatment effect estimates.\n\n::: {#ttest-and-reg-gave .cell execution_count=6}\n``` {.python .cell-code}\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.formula.api as smf\n\n# Prepare data\ngave_treat = data[data[\"treatment\"] == 1][\"gave\"].dropna()\ngave_ctrl = data[data[\"treatment\"] == 0][\"gave\"].dropna()\n\n# Group statistics\nmean_treat = gave_treat.mean()\nmean_ctrl = gave_ctrl.mean()\nstd_treat = gave_treat.std()\nstd_ctrl = gave_ctrl.std()\nn_treat = len(gave_treat)\nn_ctrl = len(gave_ctrl)\n\n# Manual t-test\nse_diff = np.sqrt((std_treat**2 / n_treat) + (std_ctrl**2 / n_ctrl))\nt_stat = (mean_treat - mean_ctrl) / se_diff\ndf = min(n_treat, n_ctrl) - 1\np_val = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n\nprint(\"Manual T-Test:\")\nprint(f\"  Mean (Treatment): {mean_treat:.4f}\")\nprint(f\"  Mean (Control):   {mean_ctrl:.4f}\")\nprint(f\"  t-statistic: {t_stat:.4f}\")\nprint(f\"  p-value:     {p_val:.4f}\")\n\n# Regression: gave ~ treatment\nmodel = smf.ols(\"gave ~ treatment\", data=data).fit()\n\nprint(\"\\nLinear Regression:\")\nprint(model.summary().tables[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nManual T-Test:\n  Mean (Treatment): 0.0220\n  Mean (Control):   0.0179\n  t-statistic: 3.2095\n  p-value:     0.0013\n\nLinear Regression:\n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\n```\n:::\n:::\n\n\nTo test whether offering a matched donation increases the likelihood of giving, we compared donation rates between the treatment group (who received a match offer) and the control group (who did not).\n\n- The t-test showed a statistically significant difference in donation rates: those who received a match offer were more likely to give.\n- The regression confirmed this result. The coefficient on `treatment` indicates that being offered a match increased the probability of giving by about 0.42 percentage points.\n\nWhile the difference may seem small in absolute terms, it is meaningful given the scale of the experiment (over 50,000 individuals). The fact that such a low-cost intervention can move behavior at all is powerful.\n\nThis finding suggests that people are more willing to give when they believe their donation is matched — even if the actual benefit is external. It aligns with the idea that charitable behavior is influenced not just by intrinsic values, but also by nudges, framing, and social cues. The presence of a matching offer makes the donation feel more impactful, and that perception increases participation.\n\n::: {#probit-gave-treatment .cell execution_count=7}\n``` {.python .cell-code}\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Run probit regression\nprobit_model = smf.probit(\"gave ~ treatment\", data=data).fit()\n\n# Print coefficient table\nprint(probit_model.summary())\n\n# Compute marginal effects at the mean (default)\nmfx = probit_model.get_margeff()\nprint(mfx.summary())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Mon, 21 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        23:57:47   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n```\n:::\n:::\n\n\nThe estimated probit coefficient on `treatment` is 0.0868, which is statistically significant (p = 0.002). The marginal effect is approximately 0.0043, meaning that receiving a matching offer increases the probability of donating by 0.43 percentage points.\n\nThis result is nearly identical to what we saw in the linear regression and t-test earlier. It reinforces the key takeaway:  \n**A simple offer to match donations meaningfully increases participation in charitable giving.**\n\nThe probit model is a better fit for binary outcomes like donation/no donation, but it leads to the same substantive conclusion — matching offers are effective nudges.\n\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n::: {#ttests-match-ratios .cell execution_count=8}\n``` {.python .cell-code}\nfrom scipy import stats\n\n# Define each group explicitly\ngroup_1to1 = data[(data[\"treatment\"] == 1) & (data[\"ratio2\"] == 0) & (data[\"ratio3\"] == 0)][\"gave\"].dropna()\ngroup_2to1 = data[data[\"ratio2\"] == 1][\"gave\"].dropna()\ngroup_3to1 = data[data[\"ratio3\"] == 1][\"gave\"].dropna()\n\n# Helper function to run and print t-test\ndef ttest_compare(label1, g1, label2, g2):\n    t_stat, p_val = stats.ttest_ind(g1, g2, equal_var=False)\n    print(f\"{label1} vs {label2}: t = {t_stat:.4f}, p = {p_val:.4f}\")\n\n# Run t-tests\nttest_compare(\"2:1\", group_2to1, \"1:1\", group_1to1)\nttest_compare(\"3:1\", group_3to1, \"1:1\", group_1to1)\nttest_compare(\"3:1\", group_3to1, \"2:1\", group_2to1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2:1 vs 1:1: t = 0.9650, p = 0.3345\n3:1 vs 1:1: t = 1.0150, p = 0.3101\n3:1 vs 2:1: t = 0.0501, p = 0.9600\n```\n:::\n:::\n\n\nWe tested whether increasing the match ratio (e.g., from 1:1 to 2:1 or 3:1) had any significant effect on the likelihood of giving. This directly addresses the authors' comment on page 8 of Karlan & List (2007) that \"*the figures suggest that increasing the match rate does little to increase the response rate.*\"\n\nOur t-tests confirm this conclusion:\n\n- The difference in donation rates between 2:1 and 1:1 was not statistically significant (p = 0.33)\n- The difference between 3:1 and 1:1 was also not significant (p = 0.31)\n- Even 3:1 vs 2:1 produced virtually no difference (p = 0.96)\n\nThese results suggest that it’s not the size of the match that matters, but simply the presence of a match offer. The behavior of donors appears consistent with psychological nudges — once motivated by a match, increasing its value doesn’t further increase giving.\n\n::: {#regression-ratio-fix .cell execution_count=9}\n``` {.python .cell-code}\n# Create ratio1 (1:1 match dummy)\ndata[\"ratio1\"] = ((data[\"treatment\"] == 1) & (data[\"ratio2\"] == 0) & (data[\"ratio3\"] == 0)).astype(int)\n\n# Filter treatment group\ntreat_data = data[data[\"treatment\"] == 1].copy()\n\n# Fix: Drop intercept explicitly\nmodel_ratios = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3 - 1\", data=treat_data).fit()\nprint(\"Regression using ratio dummies (no intercept):\")\nprint(model_ratios.summary().tables[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRegression using ratio dummies (no intercept):\n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0226      0.001     16.267      0.000       0.020       0.025\nratio3         0.0227      0.001     16.335      0.000       0.020       0.025\n==============================================================================\n```\n:::\n:::\n\n\nWe regressed the binary outcome `gave` on dummy variables for each match ratio level — 1:1, 2:1, and 3:1 — using a no-intercept model. This setup allows each coefficient to directly represent the mean response rate for that ratio group.\n\n- The response rate under a 1:1 match was 2.07%\n- Under 2:1, it was 2.26%\n- Under 3:1, it was 2.27%\n\nWhile all coefficients are statistically significant due to the large sample size, the differences between them are extremely small. Thus, the size of the match doesn’t matter — donors appear to respond to the existence of a match, not its generosity. This is consistent with behavioral theories emphasizing psychological framing over economic maximization.\n\n::: {#match-ratio-differences .cell execution_count=10}\n``` {.python .cell-code}\n# 1. Direct from data\ngroup_1to1 = data[(data[\"treatment\"] == 1) & (data[\"ratio2\"] == 0) & (data[\"ratio3\"] == 0)][\"gave\"].dropna()\ngroup_2to1 = data[data[\"ratio2\"] == 1][\"gave\"].dropna()\ngroup_3to1 = data[data[\"ratio3\"] == 1][\"gave\"].dropna()\n\nmean_1to1 = group_1to1.mean()\nmean_2to1 = group_2to1.mean()\nmean_3to1 = group_3to1.mean()\n\n# Differences in means\ndiff_2vs1 = mean_2to1 - mean_1to1\ndiff_3vs2 = mean_3to1 - mean_2to1\n\nprint(\"Direct from data:\")\nprint(f\"2:1 - 1:1 difference: {diff_2vs1:.4f}\")\nprint(f\"3:1 - 2:1 difference: {diff_3vs2:.4f}\")\n\n# 2. From regression coefficients\n# Already created in earlier code: model_ratios (regression with ratio1, ratio2, ratio3 - 1)\ncoef_1to1 = model_ratios.params[\"ratio1\"]\ncoef_2to1 = model_ratios.params[\"ratio2\"]\ncoef_3to1 = model_ratios.params[\"ratio3\"]\n\n# Differences in fitted coefficients\nreg_diff_2vs1 = coef_2to1 - coef_1to1\nreg_diff_3vs2 = coef_3to1 - coef_2to1\n\nprint(\"\\nFrom regression coefficients:\")\nprint(f\"2:1 - 1:1 difference: {reg_diff_2vs1:.4f}\")\nprint(f\"3:1 - 2:1 difference: {reg_diff_3vs2:.4f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDirect from data:\n2:1 - 1:1 difference: 0.0019\n3:1 - 2:1 difference: 0.0001\n\nFrom regression coefficients:\n2:1 - 1:1 difference: 0.0019\n3:1 - 2:1 difference: 0.0001\n```\n:::\n:::\n\n\nWe compared response rates between the three match ratio conditions (1:1, 2:1, 3:1) using two methods: directly from the data and from regression coefficients.\n\n- The difference in response rates between 2:1 and 1:1 was 0.0019 (or 0.19 percentage points)\n- The difference between 3:1 and 2:1 was just 0.0001 (0.01 percentage points)\n\nThese results are not only tiny in magnitude, but also statistically insignificant (as shown in earlier regressions and t-tests).\n\nThese findings strongly support the authors’ point that while any match offer increases giving, the size of the match does not matter. Donors seem to respond to the existence of a match — perhaps as a sign of legitimacy, urgency, or impact — but increasing the match ratio from 1:1 to 3:1 does not meaningfully increase participation.\n\nThis is a powerful insight for fundraisers: you don’t need to offer huge matches to drive behavior. Even modest matching incentives are sufficient to unlock generosity.\n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n::: {#ttest-reg-amount .cell execution_count=11}\n``` {.python .cell-code}\nfrom scipy import stats\nimport statsmodels.formula.api as smf\n\n# Drop missing values\namount_treat = data[data[\"treatment\"] == 1][\"amount\"].dropna()\namount_ctrl = data[data[\"treatment\"] == 0][\"amount\"].dropna()\n\n# T-test (two-sample, unequal variance)\nt_stat, p_val = stats.ttest_ind(amount_treat, amount_ctrl, equal_var=False)\n\nprint(\"T-Test: Donation Amount by Treatment Status\")\nprint(f\"Mean (Treatment): {amount_treat.mean():.4f}\")\nprint(f\"Mean (Control):   {amount_ctrl.mean():.4f}\")\nprint(f\"t-statistic: {t_stat:.4f}\")\nprint(f\"p-value:     {p_val:.4f}\")\n\n# Regression: amount ~ treatment\nmodel_amt = smf.ols(\"amount ~ treatment\", data=data).fit()\n\nprint(\"\\nLinear Regression: Donation Amount on Treatment\")\nprint(model_amt.summary().tables[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nT-Test: Donation Amount by Treatment Status\nMean (Treatment): 0.9669\nMean (Control):   0.8133\nt-statistic: 1.9183\np-value:     0.0551\n\nLinear Regression: Donation Amount on Treatment\n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\n```\n:::\n:::\n\n\nWe tested whether being offered a matching donation increases the average donation amount (intensive margin), using both a t-test and a linear regression.\n\n- The treatment group gave more on average than the control group\n- The difference was approximately $0.15\n- However, this difference was not statistically significant at the 5% level (p ≈ 0.06)\n\nWhile matching offers clearly increase the likelihood of donating, their effect on the amount given is less conclusive. The data suggest a positive trend, but it falls just short of conventional significance. The match offer is a strong motivator for participation (extensive margin), but its influence on donation size (intensive margin) is weaker and more variable.\n\nIn short: matching offers bring more people in, but they may not substantially increase how much each person gives.\n\n::: {#regression-amount-givers-only .cell execution_count=12}\n``` {.python .cell-code}\n# Subset to only donors\ndonors = data[data[\"gave\"] == 1].copy()\n\n# Run regression on donation amount\nimport statsmodels.formula.api as smf\nmodel_donors = smf.ols(\"amount ~ treatment\", data=donors).fit()\n\n# Show results\nprint(\"Regression: Donation Amount on Treatment (among donors only)\")\nprint(model_donors.summary().tables[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRegression: Donation Amount on Treatment (among donors only)\n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\n```\n:::\n:::\n\n\nWe now focus on those who actually made a donation, to see if the treatment influenced how much people gave, once they decided to donate.\n\nThe regression shows that donors in the treatment group gave slightly less (about $1.67) than those in the control group — but this difference is not statistically significant (p = 0.561).\n\nThis result suggests that while match offers successfully increase the number of people who give, they do not increase — and may slightly decrease — the amount given by each donor.\n\nImportantly, because we are conditioning on a post-treatment variable (`gave == 1`), we cannot interpret this coefficient causally. The treatment may have changed who donates, and those people may have different baseline donation levels. These results confirm the central insight of the paper, i.e. matching gifts are effective at increasing participation, but not at increasing donation size.\n\nIn other words, matching offers are a great tool to broaden the donor base, but they don’t necessarily make each donor more generous.\n\n::: {#cell-donation-histogram-fixed .cell execution_count=13}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\n# Subset to donors only\ndonors = data[data[\"gave\"] == 1].copy()\n\n# Debug: Check treatment value counts\nprint(\"Donor treatment group distribution:\")\nprint(donors[\"treatment\"].value_counts())\n\n# Make sure these are correct\ndonors_treat = donors[donors[\"treatment\"] == 1][\"amount\"]\ndonors_ctrl = donors[donors[\"treatment\"] == 0][\"amount\"]\n\n# Means\nmean_treat = donors_treat.mean()\nmean_ctrl = donors_ctrl.mean()\n\n# Plot\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control group\naxes[0].hist(donors_ctrl, bins=30, color='skyblue', edgecolor='white')\naxes[0].axvline(mean_ctrl, color='red', linestyle='dashed', linewidth=2)\naxes[0].set_title(\"Control Group\")\naxes[0].set_xlabel(\"Donation Amount\")\naxes[0].set_ylabel(\"Number of Donors\")\naxes[0].legend([f\"Mean = {mean_ctrl:.2f}\"], loc='upper right')\n\n# Treatment group\naxes[1].hist(donors_treat, bins=30, color='lightgreen', edgecolor='white')\naxes[1].axvline(mean_treat, color='red', linestyle='dashed', linewidth=2)\naxes[1].set_title(\"Treatment Group\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].legend([f\"Mean = {mean_treat:.2f}\"], loc='upper right')\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDonor treatment group distribution:\ntreatment\n1    736\n0    298\nName: count, dtype: int64\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Donation Amounts Among Donors (Control vs. Treatment)](index_files/figure-html/donation-histogram-fixed-output-2.png){#donation-histogram-fixed width=1141 height=468 fig-align='center'}\n:::\n:::\n\n\nThis plot compares the distribution of donation amounts among those who donated, split by treatment status.\n\n- Both distributions are right-skewed — many donors give smaller amounts, with a few larger donations.\n- The red dashed lines indicate the average donation in each group:\n  - Control group mean ≈ $45.54\n  - Treatment group mean ≈ $43.87\n\nWhile the control group donated slightly more on average than the treatment group, this difference is not statistically significant, as we saw in the conditional regression earlier.\n\nThis supports the paper’s conclusion that: Matching offers increase participation, but not donation size per donor.\n\nThe presence of a match encourages more people to give — but once they’re in, it doesn’t meaningfully change how much they give. The effectiveness of the match appears to work through activation, not through amplification.\n\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic \"works,\" in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\n\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. \n\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.\n\n### Law of Large Numbers\n\n::: {#cell-simulation-lln .cell execution_count=14}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulation parameters\nn_sim = 10_000\ncontrol_p = 0.018\ntreatment_p = 0.022\n\n# Simulate draws\ncontrol_samples = np.random.binomial(1, control_p, size=(n_sim,))\ntreatment_samples = np.random.binomial(1, treatment_p, size=(n_sim,))\n\n# Compute vector of differences\ndiffs = treatment_samples - control_samples\n\n# Cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_sim + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Average Difference\", color=\"blue\")\nplt.axhline(treatment_p - control_p, color=\"red\", linestyle=\"--\", label=\"True Difference (0.004)\")\nplt.title(\"Cumulative Average of Simulated Differences in Giving Rates\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average (Treatment - Control)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Cumulative Average of Differences in Means: Simulated LLN](index_files/figure-html/simulation-lln-output-1.png){#simulation-lln width=949 height=468 fig-align='center'}\n:::\n:::\n\n\nEach simulated draw represents a pair of Bernoulli outcomes: one from a population with a 1.8% donation rate (control), and one with a 2.2% rate (treatment). We repeat this 10,000 times, then compute the cumulative average difference in outcomes.\n\n- Early on, the average difference fluctuates due to randomness\n- As the number of simulations increases, the average stabilizes near 0.004 — the true population difference\n- This illustrates the LLN: the sample average converges to the expected value as sample size grows\n\nIt shows that even though early estimates may be noisy, with enough data, we get very close to the truth. \n\n### Central Limit Theorem\n\n::: {#cell-clt-histograms .cell execution_count=15}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Parameters\nn_simulations = 1000\nsample_sizes = [50, 200, 500, 1000]\np_control = 0.018\np_treatment = 0.022\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        diffs.append(diff)\n    \n    axes[i].hist(diffs, bins=30, color='lightblue', edgecolor='black')\n    axes[i].axvline(x=0, color='red', linestyle='--', label='Zero')\n    axes[i].axvline(x=0.004, color='green', linestyle='--', label='True Diff = 0.004')\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Mean Difference\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Central Limit Theorem: Sampling Distributions of Differences at Varying Sample Sizes](index_files/figure-html/clt-histograms-output-1.png){#clt-histograms width=1139 height=756 fig-align='center'}\n:::\n:::\n\n\nThis simulation demonstrates the Central Limit Theorem (CLT) by comparing the distribution of mean differences (treatment - control) at various sample sizes.\n\nEach plot shows the sampling distribution of mean differences across 1,000 simulated samples, at sample sizes of 50, 200, 500, and 1,000. For each simulation, we:\n- Drew `n` Bernoulli observations from a treatment group (\\( p = 0.022 \\)) and a control group (\\( p = 0.018 \\))\n- Calculated the mean difference in donation rates\n- Plotted the resulting distribution\n\nTwo reference lines are drawn on each histogram:\n- Red dashed line: Zero (null hypothesis of no effect)\n- Green dashed line: True difference (0.004)\n\nKey Insights:\n1. As sample size increases:\n   - The distribution becomes narrower (less variance)\n   - It becomes more symmetric and bell-shaped\n   - It centers more closely around the true effect of 0.004\n\n2. For small sample sizes (n = 50):\n   - The distribution is wide and noisy\n   - Zero lies near the center, so we likely wouldn’t reject the null in most replications\n\n3. For larger samples (n = 500 or 1000):\n   - The distribution is much tighter\n   - Zero lies in the tail, meaning the treatment effect would be detected as statistically significant more often\n\nThis simulation highlights how sample size affects our ability to detect treatment effects. Small samples yield imprecise, noisy estimates, even when a real effect exists. As sample size increases, our estimates:\n- Become more precise\n- Approach the true treatment effect\n- Follow the normal distribution, enabling the use of t-tests and confidence intervals\n\nIn short, the CLT tells us that with enough data, we can rely on the sample mean as a good estimator — and this explains why large-scale experiments like Karlan & List's produce reliable and robust results.\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}