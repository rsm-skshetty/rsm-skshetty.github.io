[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Samiksha Shetty",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "My Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the early 2000s, economists Dean Karlan and John List partnered with a politically oriented nonprofit organization to run a large-scale natural field experiment on charitable giving. The organization sent out over 50,000 fundraising letters to prior donors, randomly assigning each recipient to a different version of the letter.\nThe central research question was: Does offering a matching grant increase the likelihood and amount of charitable donations?\nTo answer this, recipients were randomly assigned to: - A control group that received a standard appeal, - A treatment group that was told a generous donor would match their gift at one of several ratios: 1:1, 2:1, or 3:1.\nOther variables were randomized as well: - The maximum amount of the matching grant ($25k, $50k, $100k, or unstated), - The suggested donation amount, based on their previous giving.\nThis rich experimental design allows for credible causal inference on how donors respond to match offers — both in whether they give at all (extensive margin) and how much they give (intensive margin). It’s one of the first large-scale field experiments to rigorously test “price” sensitivity in fundraising using real behavior and real money.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load mtcars dataset\nmtcars = sns.load_dataset('mpg').dropna()\n\n# Calculate displacement from horsepower and cylinders (approximate if mtcars isn't available)\n# But here we use seaborn's mpg dataset which has similar variables\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.scatterplot(data=mtcars, x='mpg', y='displacement', color='dodgerblue')\nplt.title(\"MPG vs Displacement\")\nplt.xlabel(\"Miles Per Gallon (mpg)\")\nplt.ylabel(\"Engine Displacement\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\nSamiksha \nApr 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the early 2000s, economists Dean Karlan and John List partnered with a politically oriented nonprofit organization to run a large-scale natural field experiment on charitable giving. The organization sent out over 50,000 fundraising letters to prior donors, randomly assigning each recipient to a different version of the letter.\nThe central research question was: Does offering a matching grant increase the likelihood and amount of charitable donations?\nTo answer this, recipients were randomly assigned to: - A control group that received a standard appeal, - A treatment group that was told a generous donor would match their gift at one of several ratios: 1:1, 2:1, or 3:1.\nOther variables were randomized as well: - The maximum amount of the matching grant ($25k, $50k, $100k, or unstated), - The suggested donation amount, based on their previous giving.\nThis rich experimental design allows for credible causal inference on how donors respond to match offers — both in whether they give at all (extensive margin) and how much they give (intensive margin). It’s one of the first large-scale field experiments to rigorously test “price” sensitivity in fundraising using real behavior and real money.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the early 2000s, economists Dean Karlan and John List partnered with a politically oriented nonprofit organization to run a large-scale natural field experiment on charitable giving. The organization sent out over 50,000 fundraising letters to prior donors, randomly assigning each recipient to a different version of the letter.\nThe central research question was: Does offering a matching grant increase the likelihood and amount of charitable donations?\nTo answer this, recipients were randomly assigned to: - A control group that received a standard appeal, - A treatment group that was told a generous donor would match their gift at one of several ratios: 1:1, 2:1, or 3:1.\nOther variables were randomized as well: - The maximum amount of the matching grant ($25k, $50k, $100k, or unstated), - The suggested donation amount, based on their previous giving.\nThis rich experimental design allows for credible causal inference on how donors respond to match offers — both in whether they give at all (extensive margin) and how much they give (intensive margin). It’s one of the first large-scale field experiments to rigorously test “price” sensitivity in fundraising using real behavior and real money.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\nimport pandas as pd\n\n# Load the actual dataset you just uploaded\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Preview the first few rows\ndata.head()\n\n#| label: data-summary\n#| echo: true\n\n# Summary statistics for all variables\ndata.describe(include='all')\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083\n50083.000000\n50083.000000\n50083\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nunique\nNaN\nNaN\n4\nNaN\nNaN\n5\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\ntop\nNaN\nNaN\nControl\nNaN\nNaN\nControl\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nfreq\nNaN\nNaN\n16687\nNaN\nNaN\n16687\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nmean\n0.666813\n0.333187\nNaN\n0.222311\n0.222211\nNaN\n0.166723\n0.166623\n0.166723\n0.166743\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\nNaN\n0.415803\n0.415736\nNaN\n0.372732\n0.372643\n0.372732\n0.372750\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\nNaN\n1.000000\n1.000000\nNaN\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n11 rows × 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "projects/project1/hw1_questions.html",
    "href": "projects/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the early 2000s, economists Dean Karlan and John List partnered with a politically oriented nonprofit organization to run a large-scale natural field experiment on charitable giving. The organization sent out over 50,000 fundraising letters to prior donors, randomly assigning each recipient to a different version of the letter.\nThe central research question was: Does offering a matching grant increase the likelihood and amount of charitable donations?\nTo answer this, recipients were randomly assigned to: - A control group that received a standard appeal, - A treatment group that was told a generous donor would match their gift at one of several ratios: 1:1, 2:1, or 3:1.\nOther variables were randomized as well: - The maximum amount of the matching grant ($25k, $50k, $100k, or unstated), - The suggested donation amount, based on their previous giving.\nThis rich experimental design allows for credible causal inference on how donors respond to match offers — both in whether they give at all (extensive margin) and how much they give (intensive margin). It’s one of the first large-scale field experiments to rigorously test “price” sensitivity in fundraising using real behavior and real money.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#introduction",
    "href": "projects/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the early 2000s, economists Dean Karlan and John List partnered with a politically oriented nonprofit organization to run a large-scale natural field experiment on charitable giving. The organization sent out over 50,000 fundraising letters to prior donors, randomly assigning each recipient to a different version of the letter.\nThe central research question was: Does offering a matching grant increase the likelihood and amount of charitable donations?\nTo answer this, recipients were randomly assigned to: - A control group that received a standard appeal, - A treatment group that was told a generous donor would match their gift at one of several ratios: 1:1, 2:1, or 3:1.\nOther variables were randomized as well: - The maximum amount of the matching grant ($25k, $50k, $100k, or unstated), - The suggested donation amount, based on their previous giving.\nThis rich experimental design allows for credible causal inference on how donors respond to match offers — both in whether they give at all (extensive margin) and how much they give (intensive margin). It’s one of the first large-scale field experiments to rigorously test “price” sensitivity in fundraising using real behavior and real money.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#data",
    "href": "projects/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\nimport pandas as pd\n\n# Load the actual dataset you just uploaded\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Preview the first few rows\nprint(data.head())\n\n   treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n0          0        1  Control       0       0   Control       0       0   \n1          0        1  Control       0       0   Control       0       0   \n2          1        0        1       0       0  $100,000       0       0   \n3          1        0        1       0       0  Unstated       0       0   \n4          1        0        1       0       0   $50,000       0       1   \n\n   size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n\n   ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n0       2.10          28517.0  0.499807      0.324528            1.0  \n1        NaN              NaN       NaN           NaN            NaN  \n2       2.48          51175.0  0.721941      0.192668            1.0  \n3       2.65          79269.0  0.920431      0.412142            1.0  \n4       1.85          40908.0  0.416072      0.439965            1.0  \n\n[5 rows x 51 columns]\n\n\n\n# Summary statistics for all variables\ndata.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#experimental-results",
    "href": "projects/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#simulation-experiment",
    "href": "projects/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "projects/project1/index.html#introduction",
    "href": "projects/project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nIn the early 2000s, economists Dean Karlan and John List partnered with a politically oriented nonprofit organization to run a large-scale natural field experiment on charitable giving. The organization sent out over 50,000 fundraising letters to prior donors, randomly assigning each recipient to a different version of the letter.\nThe central research question was: Does offering a matching grant increase the likelihood and amount of charitable donations?\nTo answer this, recipients were randomly assigned to: - A control group that received a standard appeal, - A treatment group that was told a generous donor would match their gift at one of several ratios: 1:1, 2:1, or 3:1.\nOther variables were randomized as well: - The maximum amount of the matching grant ($25k, $50k, $100k, or unstated), - The suggested donation amount, based on their previous giving.\nThis rich experimental design allows for credible causal inference on how donors respond to match offers — both in whether they give at all (extensive margin) and how much they give (intensive margin). It’s one of the first large-scale field experiments to rigorously test “price” sensitivity in fundraising using real behavior and real money.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/index.html#data",
    "href": "projects/project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\n# Load the actual dataset you just uploaded\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Preview the first few rows\nprint(data.head())\n\n   treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n0          0        1  Control       0       0   Control       0       0   \n1          0        1  Control       0       0   Control       0       0   \n2          1        0        1       0       0  $100,000       0       0   \n3          1        0        1       0       0  Unstated       0       0   \n4          1        0        1       0       0   $50,000       0       1   \n\n   size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n\n   ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n0       2.10          28517.0  0.499807      0.324528            1.0  \n1        NaN              NaN       NaN           NaN            NaN  \n2       2.48          51175.0  0.721941      0.192668            1.0  \n3       2.65          79269.0  0.920431      0.412142            1.0  \n4       1.85          40908.0  0.416072      0.439965            1.0  \n\n[5 rows x 51 columns]\n\n\n\nprint(data.shape)\nprint(data.info())\n\n(50083, 51)\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n\n\n\n# Summary statistics for all variables\ndata.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.formula.api as smf\n\n# Balance test on observed covariates\nbalance_vars = ['ask1', 'years', 'female', 'median_hhincome','mrm2','couple']\n\nfor var in balance_vars:\n    treated = data.loc[data['treatment'] == 1, var].dropna()\n    control = data.loc[data['treatment'] == 0, var].dropna()\n\n    x1, x2 = treated.mean(), control.mean()\n    s1, s2 = treated.std(), control.std()\n    n1, n2 = len(treated), len(control)\n\n    # Manual t-statistic (pooled standard error)\n    se = np.sqrt((s1**2 / n1) + (s2**2 / n2))\n    t_stat = (x1 - x2) / se\n    df = min(n1, n2) - 1\n    p_val = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n\n    print(f\"\\nVariable: {var}\")\n    print(f\"Manual t-test: t = {t_stat:.4f}, p = {p_val:.4f}\")\n\n    # Linear regression\n    model = smf.ols(f\"{var} ~ treatment\", data=data).fit()\n    coef = model.params['treatment']\n    p = model.pvalues['treatment']\n    print(f\"Regression: Coef = {coef:.4f}, p = {p:.4f}\")\n\n\nVariable: ask1\nManual t-test: t = 0.9730, p = 0.3306\nRegression: Coef = 0.9154, p = 0.3425\n\nVariable: years\nManual t-test: t = -1.0909, p = 0.2753\nRegression: Coef = -0.0575, p = 0.2700\n\nVariable: female\nManual t-test: t = -1.7535, p = 0.0795\nRegression: Coef = -0.0075, p = 0.0787\n\nVariable: median_hhincome\nManual t-test: t = -0.7433, p = 0.4573\nRegression: Coef = -157.9255, p = 0.4583\n\nVariable: mrm2\nManual t-test: t = 0.1195, p = 0.9049\nRegression: Coef = 0.0137, p = 0.9049\n\nVariable: couple\nManual t-test: t = -0.5823, p = 0.5604\nRegression: Coef = -0.0016, p = 0.5594\n\n\nThe balance tests above check whether the treatment and control groups differ before the intervention on observable characteristics. Key insights include: - All p-values are greater than 0.05, meaning no statistically significant differences between groups - T-test statistics and regression coefficients are numerically equivalent, confirming the equivalence of these two methods in this context\nThis result is consistent with the claim that random assignment was successful — any differences observed in donation behavior later on can be attributed to the treatment itself, not pre-existing group differences."
  },
  {
    "objectID": "projects/project1/index.html#experimental-results",
    "href": "projects/project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nTo evaluate the effect of matched donations on the likelihood of giving (i.e., the response rate), we first compare the proportion of people who donated in the treatment vs. control groups.\nBelow is a simple bar plot showing the share of donors in each group.\n\nimport matplotlib.pyplot as plt\n\n# Calculate donation rates\ndonation_rates = data.groupby(\"treatment\")[\"gave\"].mean()\nlabels = [\"Control\", \"Treatment\"]\n\n# Create bar plot\nplt.figure(figsize=(6, 4))\nbars = plt.bar(labels, donation_rates, color=[\"skyblue\", \"lightgreen\"])\nplt.title(\"Proportion of Donors by Treatment Status\")\nplt.ylabel(\"Proportion Who Donated\")\nplt.ylim(0, max(donation_rates)*1.2)\n\n# Annotate bar heights\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.0005, f\"{yval:.3f}\", ha=\"center\", va=\"bottom\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nProportion of Donors by Treatment Status\n\n\n\n\nThe bar plot shows that the treatment group — those who received a matching donation offer — had a higher donation rate than the control group.\nThis suggests that matched donations may be effective at increasing the likelihood of contributing. We’ll test the statistical significance of this next using t-tests and regression.\nWe now formally test whether the treatment group was significantly more likely to donate than the control group. We use two methods: 1. A manual t-test, comparing donation rates across groups\n2. A linear regression of gave on treatment\nThese approaches should return numerically identical p-values and treatment effect estimates.\n\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.formula.api as smf\n\n# Prepare data\ngave_treat = data[data[\"treatment\"] == 1][\"gave\"].dropna()\ngave_ctrl = data[data[\"treatment\"] == 0][\"gave\"].dropna()\n\n# Group statistics\nmean_treat = gave_treat.mean()\nmean_ctrl = gave_ctrl.mean()\nstd_treat = gave_treat.std()\nstd_ctrl = gave_ctrl.std()\nn_treat = len(gave_treat)\nn_ctrl = len(gave_ctrl)\n\n# Manual t-test\nse_diff = np.sqrt((std_treat**2 / n_treat) + (std_ctrl**2 / n_ctrl))\nt_stat = (mean_treat - mean_ctrl) / se_diff\ndf = min(n_treat, n_ctrl) - 1\np_val = 2 * (1 - stats.t.cdf(abs(t_stat), df))\n\nprint(\"Manual T-Test:\")\nprint(f\"  Mean (Treatment): {mean_treat:.4f}\")\nprint(f\"  Mean (Control):   {mean_ctrl:.4f}\")\nprint(f\"  t-statistic: {t_stat:.4f}\")\nprint(f\"  p-value:     {p_val:.4f}\")\n\n# Regression: gave ~ treatment\nmodel = smf.ols(\"gave ~ treatment\", data=data).fit()\n\nprint(\"\\nLinear Regression:\")\nprint(model.summary().tables[1])\n\nManual T-Test:\n  Mean (Treatment): 0.0220\n  Mean (Control):   0.0179\n  t-statistic: 3.2095\n  p-value:     0.0013\n\nLinear Regression:\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\n\n\nTo test whether offering a matched donation increases the likelihood of giving, we compared donation rates between the treatment group (who received a match offer) and the control group (who did not).\n\nThe t-test showed a statistically significant difference in donation rates: those who received a match offer were more likely to give.\nThe regression confirmed this result. The coefficient on treatment indicates that being offered a match increased the probability of giving by about 0.42 percentage points.\n\nWhile the difference may seem small in absolute terms, it is meaningful given the scale of the experiment (over 50,000 individuals). The fact that such a low-cost intervention can move behavior at all is powerful.\nThis finding suggests that people are more willing to give when they believe their donation is matched — even if the actual benefit is external. It aligns with the idea that charitable behavior is influenced not just by intrinsic values, but also by nudges, framing, and social cues. The presence of a matching offer makes the donation feel more impactful, and that perception increases participation.\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\n# Run probit regression\nprobit_model = smf.probit(\"gave ~ treatment\", data=data).fit()\n\n# Print coefficient table\nprint(probit_model.summary())\n\n# Compute marginal effects at the mean (default)\nmfx = probit_model.get_margeff()\nprint(mfx.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Mon, 21 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        23:57:47   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nThe estimated probit coefficient on treatment is 0.0868, which is statistically significant (p = 0.002). The marginal effect is approximately 0.0043, meaning that receiving a matching offer increases the probability of donating by 0.43 percentage points.\nThis result is nearly identical to what we saw in the linear regression and t-test earlier. It reinforces the key takeaway:\nA simple offer to match donations meaningfully increases participation in charitable giving.\nThe probit model is a better fit for binary outcomes like donation/no donation, but it leads to the same substantive conclusion — matching offers are effective nudges.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nfrom scipy import stats\n\n# Define each group explicitly\ngroup_1to1 = data[(data[\"treatment\"] == 1) & (data[\"ratio2\"] == 0) & (data[\"ratio3\"] == 0)][\"gave\"].dropna()\ngroup_2to1 = data[data[\"ratio2\"] == 1][\"gave\"].dropna()\ngroup_3to1 = data[data[\"ratio3\"] == 1][\"gave\"].dropna()\n\n# Helper function to run and print t-test\ndef ttest_compare(label1, g1, label2, g2):\n    t_stat, p_val = stats.ttest_ind(g1, g2, equal_var=False)\n    print(f\"{label1} vs {label2}: t = {t_stat:.4f}, p = {p_val:.4f}\")\n\n# Run t-tests\nttest_compare(\"2:1\", group_2to1, \"1:1\", group_1to1)\nttest_compare(\"3:1\", group_3to1, \"1:1\", group_1to1)\nttest_compare(\"3:1\", group_3to1, \"2:1\", group_2to1)\n\n2:1 vs 1:1: t = 0.9650, p = 0.3345\n3:1 vs 1:1: t = 1.0150, p = 0.3101\n3:1 vs 2:1: t = 0.0501, p = 0.9600\n\n\nWe tested whether increasing the match ratio (e.g., from 1:1 to 2:1 or 3:1) had any significant effect on the likelihood of giving. This directly addresses the authors’ comment on page 8 of Karlan & List (2007) that “the figures suggest that increasing the match rate does little to increase the response rate.”\nOur t-tests confirm this conclusion:\n\nThe difference in donation rates between 2:1 and 1:1 was not statistically significant (p = 0.33)\nThe difference between 3:1 and 1:1 was also not significant (p = 0.31)\nEven 3:1 vs 2:1 produced virtually no difference (p = 0.96)\n\nThese results suggest that it’s not the size of the match that matters, but simply the presence of a match offer. The behavior of donors appears consistent with psychological nudges — once motivated by a match, increasing its value doesn’t further increase giving.\n\n# Create ratio1 (1:1 match dummy)\ndata[\"ratio1\"] = ((data[\"treatment\"] == 1) & (data[\"ratio2\"] == 0) & (data[\"ratio3\"] == 0)).astype(int)\n\n# Filter treatment group\ntreat_data = data[data[\"treatment\"] == 1].copy()\n\n# Fix: Drop intercept explicitly\nmodel_ratios = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3 - 1\", data=treat_data).fit()\nprint(\"Regression using ratio dummies (no intercept):\")\nprint(model_ratios.summary().tables[1])\n\nRegression using ratio dummies (no intercept):\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0226      0.001     16.267      0.000       0.020       0.025\nratio3         0.0227      0.001     16.335      0.000       0.020       0.025\n==============================================================================\n\n\nWe regressed the binary outcome gave on dummy variables for each match ratio level — 1:1, 2:1, and 3:1 — using a no-intercept model. This setup allows each coefficient to directly represent the mean response rate for that ratio group.\n\nThe response rate under a 1:1 match was 2.07%\nUnder 2:1, it was 2.26%\nUnder 3:1, it was 2.27%\n\nWhile all coefficients are statistically significant due to the large sample size, the differences between them are extremely small. Thus, the size of the match doesn’t matter — donors appear to respond to the existence of a match, not its generosity. This is consistent with behavioral theories emphasizing psychological framing over economic maximization.\n\n# 1. Direct from data\ngroup_1to1 = data[(data[\"treatment\"] == 1) & (data[\"ratio2\"] == 0) & (data[\"ratio3\"] == 0)][\"gave\"].dropna()\ngroup_2to1 = data[data[\"ratio2\"] == 1][\"gave\"].dropna()\ngroup_3to1 = data[data[\"ratio3\"] == 1][\"gave\"].dropna()\n\nmean_1to1 = group_1to1.mean()\nmean_2to1 = group_2to1.mean()\nmean_3to1 = group_3to1.mean()\n\n# Differences in means\ndiff_2vs1 = mean_2to1 - mean_1to1\ndiff_3vs2 = mean_3to1 - mean_2to1\n\nprint(\"Direct from data:\")\nprint(f\"2:1 - 1:1 difference: {diff_2vs1:.4f}\")\nprint(f\"3:1 - 2:1 difference: {diff_3vs2:.4f}\")\n\n# 2. From regression coefficients\n# Already created in earlier code: model_ratios (regression with ratio1, ratio2, ratio3 - 1)\ncoef_1to1 = model_ratios.params[\"ratio1\"]\ncoef_2to1 = model_ratios.params[\"ratio2\"]\ncoef_3to1 = model_ratios.params[\"ratio3\"]\n\n# Differences in fitted coefficients\nreg_diff_2vs1 = coef_2to1 - coef_1to1\nreg_diff_3vs2 = coef_3to1 - coef_2to1\n\nprint(\"\\nFrom regression coefficients:\")\nprint(f\"2:1 - 1:1 difference: {reg_diff_2vs1:.4f}\")\nprint(f\"3:1 - 2:1 difference: {reg_diff_3vs2:.4f}\")\n\nDirect from data:\n2:1 - 1:1 difference: 0.0019\n3:1 - 2:1 difference: 0.0001\n\nFrom regression coefficients:\n2:1 - 1:1 difference: 0.0019\n3:1 - 2:1 difference: 0.0001\n\n\nWe compared response rates between the three match ratio conditions (1:1, 2:1, 3:1) using two methods: directly from the data and from regression coefficients.\n\nThe difference in response rates between 2:1 and 1:1 was 0.0019 (or 0.19 percentage points)\nThe difference between 3:1 and 2:1 was just 0.0001 (0.01 percentage points)\n\nThese results are not only tiny in magnitude, but also statistically insignificant (as shown in earlier regressions and t-tests).\nThese findings strongly support the authors’ point that while any match offer increases giving, the size of the match does not matter. Donors seem to respond to the existence of a match — perhaps as a sign of legitimacy, urgency, or impact — but increasing the match ratio from 1:1 to 3:1 does not meaningfully increase participation.\nThis is a powerful insight for fundraisers: you don’t need to offer huge matches to drive behavior. Even modest matching incentives are sufficient to unlock generosity.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nfrom scipy import stats\nimport statsmodels.formula.api as smf\n\n# Drop missing values\namount_treat = data[data[\"treatment\"] == 1][\"amount\"].dropna()\namount_ctrl = data[data[\"treatment\"] == 0][\"amount\"].dropna()\n\n# T-test (two-sample, unequal variance)\nt_stat, p_val = stats.ttest_ind(amount_treat, amount_ctrl, equal_var=False)\n\nprint(\"T-Test: Donation Amount by Treatment Status\")\nprint(f\"Mean (Treatment): {amount_treat.mean():.4f}\")\nprint(f\"Mean (Control):   {amount_ctrl.mean():.4f}\")\nprint(f\"t-statistic: {t_stat:.4f}\")\nprint(f\"p-value:     {p_val:.4f}\")\n\n# Regression: amount ~ treatment\nmodel_amt = smf.ols(\"amount ~ treatment\", data=data).fit()\n\nprint(\"\\nLinear Regression: Donation Amount on Treatment\")\nprint(model_amt.summary().tables[1])\n\nT-Test: Donation Amount by Treatment Status\nMean (Treatment): 0.9669\nMean (Control):   0.8133\nt-statistic: 1.9183\np-value:     0.0551\n\nLinear Regression: Donation Amount on Treatment\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\n\n\nWe tested whether being offered a matching donation increases the average donation amount (intensive margin), using both a t-test and a linear regression.\n\nThe treatment group gave more on average than the control group\nThe difference was approximately $0.15\nHowever, this difference was not statistically significant at the 5% level (p ≈ 0.06)\n\nWhile matching offers clearly increase the likelihood of donating, their effect on the amount given is less conclusive. The data suggest a positive trend, but it falls just short of conventional significance. The match offer is a strong motivator for participation (extensive margin), but its influence on donation size (intensive margin) is weaker and more variable.\nIn short: matching offers bring more people in, but they may not substantially increase how much each person gives.\n\n# Subset to only donors\ndonors = data[data[\"gave\"] == 1].copy()\n\n# Run regression on donation amount\nimport statsmodels.formula.api as smf\nmodel_donors = smf.ols(\"amount ~ treatment\", data=donors).fit()\n\n# Show results\nprint(\"Regression: Donation Amount on Treatment (among donors only)\")\nprint(model_donors.summary().tables[1])\n\nRegression: Donation Amount on Treatment (among donors only)\n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\n\n\nWe now focus on those who actually made a donation, to see if the treatment influenced how much people gave, once they decided to donate.\nThe regression shows that donors in the treatment group gave slightly less (about $1.67) than those in the control group — but this difference is not statistically significant (p = 0.561).\nThis result suggests that while match offers successfully increase the number of people who give, they do not increase — and may slightly decrease — the amount given by each donor.\nImportantly, because we are conditioning on a post-treatment variable (gave == 1), we cannot interpret this coefficient causally. The treatment may have changed who donates, and those people may have different baseline donation levels. These results confirm the central insight of the paper, i.e. matching gifts are effective at increasing participation, but not at increasing donation size.\nIn other words, matching offers are a great tool to broaden the donor base, but they don’t necessarily make each donor more generous.\n\nimport matplotlib.pyplot as plt\n\n# Subset to donors only\ndonors = data[data[\"gave\"] == 1].copy()\n\n# Debug: Check treatment value counts\nprint(\"Donor treatment group distribution:\")\nprint(donors[\"treatment\"].value_counts())\n\n# Make sure these are correct\ndonors_treat = donors[donors[\"treatment\"] == 1][\"amount\"]\ndonors_ctrl = donors[donors[\"treatment\"] == 0][\"amount\"]\n\n# Means\nmean_treat = donors_treat.mean()\nmean_ctrl = donors_ctrl.mean()\n\n# Plot\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control group\naxes[0].hist(donors_ctrl, bins=30, color='skyblue', edgecolor='white')\naxes[0].axvline(mean_ctrl, color='red', linestyle='dashed', linewidth=2)\naxes[0].set_title(\"Control Group\")\naxes[0].set_xlabel(\"Donation Amount\")\naxes[0].set_ylabel(\"Number of Donors\")\naxes[0].legend([f\"Mean = {mean_ctrl:.2f}\"], loc='upper right')\n\n# Treatment group\naxes[1].hist(donors_treat, bins=30, color='lightgreen', edgecolor='white')\naxes[1].axvline(mean_treat, color='red', linestyle='dashed', linewidth=2)\naxes[1].set_title(\"Treatment Group\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].legend([f\"Mean = {mean_treat:.2f}\"], loc='upper right')\n\nplt.tight_layout()\nplt.show()\n\nDonor treatment group distribution:\ntreatment\n1    736\n0    298\nName: count, dtype: int64\n\n\n\n\n\nDonation Amounts Among Donors (Control vs. Treatment)\n\n\n\n\nThis plot compares the distribution of donation amounts among those who donated, split by treatment status.\n\nBoth distributions are right-skewed — many donors give smaller amounts, with a few larger donations.\nThe red dashed lines indicate the average donation in each group:\n\nControl group mean ≈ $45.54\nTreatment group mean ≈ $43.87\n\n\nWhile the control group donated slightly more on average than the treatment group, this difference is not statistically significant, as we saw in the conditional regression earlier.\nThis supports the paper’s conclusion that: Matching offers increase participation, but not donation size per donor.\nThe presence of a match encourages more people to give — but once they’re in, it doesn’t meaningfully change how much they give. The effectiveness of the match appears to work through activation, not through amplification."
  },
  {
    "objectID": "projects/project1/index.html#simulation-experiment",
    "href": "projects/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulation parameters\nn_sim = 10_000\ncontrol_p = 0.018\ntreatment_p = 0.022\n\n# Simulate draws\ncontrol_samples = np.random.binomial(1, control_p, size=(n_sim,))\ntreatment_samples = np.random.binomial(1, treatment_p, size=(n_sim,))\n\n# Compute vector of differences\ndiffs = treatment_samples - control_samples\n\n# Cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_sim + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label=\"Cumulative Average Difference\", color=\"blue\")\nplt.axhline(treatment_p - control_p, color=\"red\", linestyle=\"--\", label=\"True Difference (0.004)\")\nplt.title(\"Cumulative Average of Simulated Differences in Giving Rates\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average (Treatment - Control)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\nCumulative Average of Differences in Means: Simulated LLN\n\n\n\n\nEach simulated draw represents a pair of Bernoulli outcomes: one from a population with a 1.8% donation rate (control), and one with a 2.2% rate (treatment). We repeat this 10,000 times, then compute the cumulative average difference in outcomes.\n\nEarly on, the average difference fluctuates due to randomness\nAs the number of simulations increases, the average stabilizes near 0.004 — the true population difference\nThis illustrates the LLN: the sample average converges to the expected value as sample size grows\n\nIt shows that even though early estimates may be noisy, with enough data, we get very close to the truth.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Parameters\nn_simulations = 1000\nsample_sizes = [50, 200, 500, 1000]\np_control = 0.018\np_treatment = 0.022\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        diffs.append(diff)\n    \n    axes[i].hist(diffs, bins=30, color='lightblue', edgecolor='black')\n    axes[i].axvline(x=0, color='red', linestyle='--', label='Zero')\n    axes[i].axvline(x=0.004, color='green', linestyle='--', label='True Diff = 0.004')\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Mean Difference\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCentral Limit Theorem: Sampling Distributions of Differences at Varying Sample Sizes\n\n\n\n\nThis simulation demonstrates the Central Limit Theorem (CLT) by comparing the distribution of mean differences (treatment - control) at various sample sizes.\nEach plot shows the sampling distribution of mean differences across 1,000 simulated samples, at sample sizes of 50, 200, 500, and 1,000. For each simulation, we: - Drew n Bernoulli observations from a treatment group (( p = 0.022 )) and a control group (( p = 0.018 )) - Calculated the mean difference in donation rates - Plotted the resulting distribution\nTwo reference lines are drawn on each histogram: - Red dashed line: Zero (null hypothesis of no effect) - Green dashed line: True difference (0.004)\nKey Insights: 1. As sample size increases: - The distribution becomes narrower (less variance) - It becomes more symmetric and bell-shaped - It centers more closely around the true effect of 0.004\n\nFor small sample sizes (n = 50):\n\nThe distribution is wide and noisy\nZero lies near the center, so we likely wouldn’t reject the null in most replications\n\nFor larger samples (n = 500 or 1000):\n\nThe distribution is much tighter\nZero lies in the tail, meaning the treatment effect would be detected as statistically significant more often\n\n\nThis simulation highlights how sample size affects our ability to detect treatment effects. Small samples yield imprecise, noisy estimates, even when a real effect exists. As sample size increases, our estimates: - Become more precise - Approach the true treatment effect - Follow the normal distribution, enabling the use of t-tests and confidence intervals\nIn short, the CLT tells us that with enough data, we can rely on the sample mean as a good estimator — and this explains why large-scale experiments like Karlan & List’s produce reliable and robust results."
  },
  {
    "objectID": "index_project1.html",
    "href": "index_project1.html",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Let’s investigate the relationship between fuel efficiency (mpg) and engine displacement (disp) from the mtcars dataset. Those variables have a correlation of r cor(mtcars$mpg, mtcars$disp) |&gt; format(digits=2).\n\n\nHere is a plot:\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load mtcars dataset\nmtcars = sns.load_dataset('mpg').dropna()\n\n# Calculate displacement from horsepower and cylinders (approximate if mtcars isn't available)\n# But here we use seaborn's mpg dataset which has similar variables\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.scatterplot(data=mtcars, x='mpg', y='displacement', color='dodgerblue')\nplt.title(\"MPG vs Displacement\")\nplt.xlabel(\"Miles Per Gallon (mpg)\")\nplt.ylabel(\"Engine Displacement\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "index_project1.html#sub-header",
    "href": "index_project1.html#sub-header",
    "title": "Analysis of Cars",
    "section": "",
    "text": "Here is a plot:\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load mtcars dataset\nmtcars = sns.load_dataset('mpg').dropna()\n\n# Calculate displacement from horsepower and cylinders (approximate if mtcars isn't available)\n# But here we use seaborn's mpg dataset which has similar variables\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.scatterplot(data=mtcars, x='mpg', y='displacement', color='dodgerblue')\nplt.title(\"MPG vs Displacement\")\nplt.xlabel(\"Miles Per Gallon (mpg)\")\nplt.ylabel(\"Engine Displacement\")\nplt.tight_layout()\nplt.show()"
  }
]